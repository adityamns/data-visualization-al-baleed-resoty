{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè® Al Baleed Resort Salalah - Comprehensive Data Analysis\n",
    "## From Descriptive to Prescriptive Analytics\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset:** Al Baleed Resort Salalah by Anantara - TripAdvisor Reviews  \n",
    "**Total Reviews:** 1,347  \n",
    "**Analysis Framework:** 6-Phase Analytics (Descriptive ‚Üí Prescriptive)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. **Setup & Data Loading**\n",
    "2. **Data Cleaning**\n",
    "3. **Feature Engineering** (Phase 2)\n",
    "4. **Descriptive Analytics** (Phase 3)\n",
    "5. **Diagnostic Analytics** (Phase 4)\n",
    "6. **Predictive Analytics** (Phase 5)\n",
    "7. **Prescriptive Analytics** (Phase 6)\n",
    "8. **Conclusion & Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. üì¶ Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Text Processing\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_excel('Al_Baleed_Resort.xlsx')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä DATASET LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìå Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nüìÖ Columns: {list(df.columns)}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Data Exploration\n",
    "print(\"üîç INITIAL DATA EXPLORATION\\n\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüìä Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"üîç MISSING VALUES ANALYSIS\\n\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "print(f\"\\n‚ö†Ô∏è User Location has {missing_df.loc['User Location', 'Percentage']:.1f}% missing values\")\n",
    "print(f\"‚ö†Ô∏è Stay Date has {missing_df.loc['Stay Date', 'Missing Count']:.0f} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. üßπ Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"üßπ DATA CLEANING PROCESS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Handle missing User Location (fill with 'Unknown')\n",
    "df_clean['User Location'].fillna('Unknown', inplace=True)\n",
    "print(\"‚úÖ Step 1: Filled missing User Location with 'Unknown'\")\n",
    "\n",
    "# 2. Handle missing Stay Date (drop only 2 rows)\n",
    "before_drop = len(df_clean)\n",
    "df_clean.dropna(subset=['Stay Date'], inplace=True)\n",
    "print(f\"‚úÖ Step 2: Dropped {before_drop - len(df_clean)} rows with missing Stay Date\")\n",
    "\n",
    "# 3. Convert date columns to datetime\n",
    "df_clean['Stay Date'] = pd.to_datetime(df_clean['Stay Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df_clean['Created Date'] = pd.to_datetime(df_clean['Created Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df_clean['Published Date'] = pd.to_datetime(df_clean['Published Date'], format='%d/%m/%Y', errors='coerce')\n",
    "print(\"‚úÖ Step 3: Converted date columns to datetime format\")\n",
    "\n",
    "# 4. Remove any duplicates\n",
    "before_dedup = len(df_clean)\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "print(f\"‚úÖ Step 4: Removed {before_dedup - len(df_clean)} duplicate rows\")\n",
    "\n",
    "# 5. Strip whitespace from text columns\n",
    "text_cols = ['Hotel Name', 'User Location', 'Review Title', 'Review Text', 'Trip Type', 'Language']\n",
    "for col in text_cols:\n",
    "    df_clean[col] = df_clean[col].str.strip()\n",
    "print(\"‚úÖ Step 5: Cleaned whitespace from text columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"\\nüìä FINAL DATASET: {len(df_clean)} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(\"‚úÖ Data cleaning completed successfully!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. üîß FEATURE ENGINEERING (Phase 2)\n",
    "\n",
    "Creating new features to enhance our analysis:\n",
    "- Date features (Year, Month, Day Name, Is Weekend)\n",
    "- Seasonality (High Season vs Low Season)\n",
    "- Review characteristics (length, word count)\n",
    "- Sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß FEATURE ENGINEERING\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Extract Date Features\n",
    "df_clean['Year'] = df_clean['Stay Date'].dt.year\n",
    "df_clean['Month'] = df_clean['Stay Date'].dt.month\n",
    "df_clean['Month_Name'] = df_clean['Stay Date'].dt.strftime('%B')\n",
    "df_clean['Day_Name'] = df_clean['Stay Date'].dt.strftime('%A')\n",
    "df_clean['Is_Weekend'] = df_clean['Stay Date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "print(\"‚úÖ Feature 1: Date features extracted (Year, Month, Day_Name, Is_Weekend)\")\n",
    "\n",
    "# 2. Seasonality (Salalah specific)\n",
    "# Khareef (Monsoon/High Season): June-September\n",
    "# Low Season: October-May\n",
    "def get_season(month):\n",
    "    if month in [6, 7, 8, 9]:  # June-September\n",
    "        return 'High Season (Khareef)'\n",
    "    else:\n",
    "        return 'Low Season'\n",
    "\n",
    "df_clean['Season'] = df_clean['Month'].apply(get_season)\n",
    "print(\"‚úÖ Feature 2: Seasonality created (Khareef Season: Jun-Sep)\")\n",
    "\n",
    "# 3. Review Length Features\n",
    "df_clean['Review_Length_Chars'] = df_clean['Review Text'].str.len()\n",
    "df_clean['Review_Length_Words'] = df_clean['Review Text'].str.split().str.len()\n",
    "print(\"‚úÖ Feature 3: Review length calculated (characters & words)\")\n",
    "\n",
    "# 4. Sentiment Label\n",
    "def get_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 'Positive'\n",
    "    elif rating == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "df_clean['Sentiment'] = df_clean['Rating'].apply(get_sentiment)\n",
    "print(\"‚úÖ Feature 4: Sentiment labels created (Positive: 4-5, Neutral: 3, Negative: 1-2)\")\n",
    "\n",
    "# 5. Average Service Score\n",
    "service_cols = ['Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality']\n",
    "df_clean['Avg_Service_Score'] = df_clean[service_cols].mean(axis=1)\n",
    "print(\"‚úÖ Feature 5: Average service score calculated\")\n",
    "\n",
    "# 6. Service Score Variance (consistency)\n",
    "df_clean['Service_Score_Variance'] = df_clean[service_cols].var(axis=1)\n",
    "print(\"‚úÖ Feature 6: Service score variance calculated (consistency measure)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"\\nüìä NEW FEATURES ADDED: {len(df_clean.columns) - len(df.columns)} features\")\n",
    "print(\"‚úÖ Feature engineering completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of new features\n",
    "print(\"üìå Sample of Engineered Features:\\n\")\n",
    "display_cols = ['Rating', 'Stay Date', 'Year', 'Month_Name', 'Day_Name', 'Is_Weekend', \n",
    "                'Season', 'Review_Length_Words', 'Sentiment', 'Avg_Service_Score']\n",
    "df_clean[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. üìä DESCRIPTIVE ANALYTICS (Phase 3 - \"What Happened?\")\n",
    "\n",
    "Understanding the data through univariate and bivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Overview & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä FINAL DATASET OVERVIEW\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Reviews: {len(df_clean):,}\")\n",
    "print(f\"Date Range: {df_clean['Stay Date'].min().strftime('%B %Y')} - {df_clean['Stay Date'].max().strftime('%B %Y')}\")\n",
    "print(f\"Total Columns: {df_clean.shape[1]}\")\n",
    "print(f\"\\nAverage Rating: {df_clean['Rating'].mean():.2f} / 5.0\")\n",
    "print(f\"Average Review Length: {df_clean['Review_Length_Words'].mean():.0f} words\")\n",
    "print(f\"\\nSentiment Distribution:\")\n",
    "print(df_clean['Sentiment'].value_counts())\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Rating (Pie Chart & Bar Chart)\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Rating Distribution (Pie Chart)', 'Rating Distribution (Bar Chart)'),\n",
    "    specs=[[{'type': 'pie'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Pie chart\n",
    "rating_counts = df_clean['Rating'].value_counts().sort_index()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=rating_counts.index, values=rating_counts.values, \n",
    "           textinfo='label+percent', hole=0.3),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bar chart\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rating_counts.index, y=rating_counts.values, \n",
    "           text=rating_counts.values, textposition='auto',\n",
    "           marker_color=['#d62728', '#ff7f0e', '#ffbb78', '#2ca02c', '#1f77b4']),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400, showlegend=False, title_text=\"Overall Rating Distribution\")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Rating Distribution:\")\n",
    "for rating, count in rating_counts.items():\n",
    "    pct = (count / len(df_clean)) * 100\n",
    "    print(f\"‚≠ê {rating} Star: {count:4d} reviews ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Aspect Scores (Bar Chart)\n",
    "service_aspects = ['Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality']\n",
    "avg_scores = df_clean[service_aspects].mean().sort_values(ascending=False)\n",
    "\n",
    "fig = px.bar(x=avg_scores.index, y=avg_scores.values, \n",
    "             labels={'x': 'Service Aspect', 'y': 'Average Score (0-5)'},\n",
    "             title='Average Scores by Service Aspect',\n",
    "             text=avg_scores.values.round(2))\n",
    "fig.update_traces(textposition='outside', marker_color='lightblue')\n",
    "fig.update_layout(height=400, yaxis_range=[0, 5.5])\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Service Aspect Rankings:\")\n",
    "for i, (aspect, score) in enumerate(avg_scores.items(), 1):\n",
    "    print(f\"{i}. {aspect:15s}: {score:.2f} / 5.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip Type Distribution\n",
    "trip_counts = df_clean['Trip Type'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=trip_counts.index, y=trip_counts.values, \n",
    "           text=trip_counts.values, textposition='auto',\n",
    "           marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "])\n",
    "fig.update_layout(title='Distribution of Trip Types',\n",
    "                  xaxis_title='Trip Type', yaxis_title='Number of Reviews',\n",
    "                  height=400)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Trip Type Distribution:\")\n",
    "for trip_type, count in trip_counts.items():\n",
    "    pct = (count / len(df_clean)) * 100\n",
    "    print(f\"üë• {trip_type:10s}: {count:4d} reviews ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating vs Trip Type (Boxplot)\n",
    "fig = px.box(df_clean, x='Trip Type', y='Rating', \n",
    "             title='Rating Distribution by Trip Type',\n",
    "             color='Trip Type',\n",
    "             labels={'Rating': 'Rating (1-5)'})\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nüìä Average Rating by Trip Type:\")\n",
    "trip_rating = df_clean.groupby('Trip Type')['Rating'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "for trip_type, row in trip_rating.iterrows():\n",
    "    print(f\"{trip_type:10s}: {row['mean']:.2f} ‚≠ê (n={row['count']:.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating vs Month (Time Series)\n",
    "monthly_rating = df_clean.groupby('Month_Name')['Rating'].mean().reindex(\n",
    "    ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "     'July', 'August', 'September', 'October', 'November', 'December']\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=monthly_rating.index, y=monthly_rating.values,\n",
    "                         mode='lines+markers', name='Average Rating',\n",
    "                         line=dict(width=3), marker=dict(size=10)))\n",
    "fig.update_layout(title='Average Rating by Month',\n",
    "                  xaxis_title='Month', yaxis_title='Average Rating',\n",
    "                  height=400, yaxis_range=[4, 5])\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Monthly Rating Trend:\")\n",
    "for month, rating in monthly_rating.items():\n",
    "    if not pd.isna(rating):\n",
    "        print(f\"{month:10s}: {rating:.2f} ‚≠ê\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Length vs Rating\n",
    "fig = px.scatter(df_clean, x='Review_Length_Words', y='Rating', \n",
    "                 color='Sentiment',\n",
    "                 title='Review Length vs Rating',\n",
    "                 labels={'Review_Length_Words': 'Review Length (words)', 'Rating': 'Rating (1-5)'},\n",
    "                 opacity=0.6, trendline='ols')\n",
    "fig.update_layout(height=400)\n",
    "fig.show()\n",
    "\n",
    "# Correlation\n",
    "corr = df_clean[['Review_Length_Words', 'Rating']].corr().iloc[0, 1]\n",
    "print(f\"\\nüìä Correlation between Review Length and Rating: {corr:.3f}\")\n",
    "if corr < 0:\n",
    "    print(\"   ‚Üí Negative correlation: Longer reviews tend to have lower ratings\")\n",
    "else:\n",
    "    print(\"   ‚Üí Positive correlation: Longer reviews tend to have higher ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating by Season\n",
    "season_rating = df_clean.groupby('Season')['Rating'].agg(['mean', 'count'])\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=season_rating.index, y=season_rating['mean'], \n",
    "           text=season_rating['mean'].round(2), textposition='auto',\n",
    "           marker_color=['#2ca02c', '#ff7f0e'])\n",
    "])\n",
    "fig.update_layout(title='Average Rating by Season',\n",
    "                  xaxis_title='Season', yaxis_title='Average Rating',\n",
    "                  height=400, yaxis_range=[4, 5])\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìä Rating by Season:\")\n",
    "for season, row in season_rating.iterrows():\n",
    "    print(f\"{season:25s}: {row['mean']:.2f} ‚≠ê (n={row['count']:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. üî¨ DIAGNOSTIC ANALYTICS (Phase 4 - \"Why it Happened?\")\n",
    "\n",
    "Deep dive into correlations, text analysis, and root cause identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap: Rating vs Service Aspects\n",
    "corr_cols = ['Rating', 'Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality']\n",
    "corr_matrix = df_clean[corr_cols].corr()\n",
    "\n",
    "fig = px.imshow(corr_matrix, \n",
    "                labels=dict(color=\"Correlation\"),\n",
    "                x=corr_matrix.columns, y=corr_matrix.columns,\n",
    "                color_continuous_scale='RdBu_r',\n",
    "                title='Correlation Heatmap: Rating vs Service Aspects',\n",
    "                text_auto='.2f')\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüî¨ Correlation with Overall Rating:\\n\")\n",
    "rating_corr = corr_matrix['Rating'].drop('Rating').sort_values(ascending=False)\n",
    "for aspect, corr in rating_corr.items():\n",
    "    print(f\"{aspect:15s}: {corr:+.3f} {'üî¥' if corr > 0.5 else 'üü°' if corr > 0.3 else 'üü¢'}\")\n",
    "\n",
    "print(f\"\\nüí° Top 3 Most Influential Aspects:\")\n",
    "for i, (aspect, corr) in enumerate(rating_corr.head(3).items(), 1):\n",
    "    print(f\"   {i}. {aspect}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Text Mining & Keyword Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Positive Reviews (5 stars)\n",
    "positive_reviews = df_clean[df_clean['Rating'] == 5]['Review Text'].str.cat(sep=' ')\n",
    "\n",
    "# Clean text\n",
    "positive_reviews = positive_reviews.lower()\n",
    "positive_reviews = re.sub(r'[^a-z\\s]', '', positive_reviews)\n",
    "\n",
    "wordcloud_positive = WordCloud(width=800, height=400, \n",
    "                                background_color='white',\n",
    "                                colormap='Greens',\n",
    "                                max_words=100,\n",
    "                                stopwords={'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "                                          'of', 'with', 'is', 'was', 'were', 'are', 'been', 'be', 'have', 'has',\n",
    "                                          'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may',\n",
    "                                          'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'we',\n",
    "                                          'you', 'he', 'she', 'it', 'they', 'them', 'their', 'my', 'your', 'his',\n",
    "                                          'her', 'its', 'our', 'resort', 'hotel', 'stay', 'stayed'}).generate(positive_reviews)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud: 5-Star Reviews (Positive)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Negative Reviews (1-2 stars)\n",
    "negative_reviews = df_clean[df_clean['Rating'] <= 2]['Review Text'].str.cat(sep=' ')\n",
    "\n",
    "if len(negative_reviews) > 50:  # Only if we have enough text\n",
    "    negative_reviews = negative_reviews.lower()\n",
    "    negative_reviews = re.sub(r'[^a-z\\s]', '', negative_reviews)\n",
    "    \n",
    "    wordcloud_negative = WordCloud(width=800, height=400, \n",
    "                                    background_color='white',\n",
    "                                    colormap='Reds',\n",
    "                                    max_words=100,\n",
    "                                    stopwords={'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "                                              'of', 'with', 'is', 'was', 'were', 'are', 'been', 'be', 'have', 'has',\n",
    "                                              'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may',\n",
    "                                              'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'we',\n",
    "                                              'you', 'he', 'she', 'it', 'they', 'them', 'their', 'my', 'your', 'his',\n",
    "                                              'her', 'its', 'our', 'resort', 'hotel', 'stay', 'stayed'}).generate(negative_reviews)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud: 1-2 Star Reviews (Negative)', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough negative reviews for word cloud analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Grams (Bi-grams) Analysis\n",
    "from collections import Counter\n",
    "\n",
    "def get_bigrams(text, n=20):\n",
    "    \"\"\"Extract top N bi-grams from text\"\"\"\n",
    "    words = text.lower().split()\n",
    "    # Remove common stopwords\n",
    "    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'is', 'was', 'were'}\n",
    "    words = [w for w in words if w not in stopwords and len(w) > 2]\n",
    "    \n",
    "    bigrams = [' '.join([words[i], words[i+1]]) for i in range(len(words)-1)]\n",
    "    return Counter(bigrams).most_common(n)\n",
    "\n",
    "# Positive reviews bigrams\n",
    "print(\"\\nüìä TOP 15 BI-GRAMS IN 5-STAR REVIEWS:\\n\")\n",
    "positive_bigrams = get_bigrams(positive_reviews, 15)\n",
    "for i, (bigram, count) in enumerate(positive_bigrams, 1):\n",
    "    print(f\"{i:2d}. '{bigram}' - {count} times\")\n",
    "\n",
    "# Visualize\n",
    "bigrams_df = pd.DataFrame(positive_bigrams, columns=['Bigram', 'Count'])\n",
    "fig = px.bar(bigrams_df, x='Count', y='Bigram', orientation='h',\n",
    "             title='Top 15 Bi-grams in 5-Star Reviews',\n",
    "             labels={'Count': 'Frequency'})\n",
    "fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews bigrams (if available)\n",
    "if len(df_clean[df_clean['Rating'] <= 2]) >= 5:\n",
    "    print(\"\\nüìä TOP 10 BI-GRAMS IN 1-2 STAR REVIEWS:\\n\")\n",
    "    negative_bigrams = get_bigrams(negative_reviews, 10)\n",
    "    for i, (bigram, count) in enumerate(negative_bigrams, 1):\n",
    "        print(f\"{i:2d}. '{bigram}' - {count} times\")\n",
    "    \n",
    "    # Visualize\n",
    "    neg_bigrams_df = pd.DataFrame(negative_bigrams, columns=['Bigram', 'Count'])\n",
    "    fig = px.bar(neg_bigrams_df, x='Count', y='Bigram', orientation='h',\n",
    "                 title='Top 10 Bi-grams in 1-2 Star Reviews',\n",
    "                 labels={'Count': 'Frequency'},\n",
    "                 color_discrete_sequence=['#d62728'])\n",
    "    fig.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Root Cause Analysis (Negative Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into negative reviews\n",
    "negative_df = df_clean[df_clean['Rating'] <= 2].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üî¥ ROOT CAUSE ANALYSIS: NEGATIVE REVIEWS (1-2 STARS)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal Negative Reviews: {len(negative_df)} ({(len(negative_df)/len(df_clean)*100):.1f}%)\\n\")\n",
    "\n",
    "if len(negative_df) > 0:\n",
    "    # Service aspect scores in negative reviews\n",
    "    print(\"üìä Average Service Scores in Negative Reviews:\\n\")\n",
    "    service_aspects = ['Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality']\n",
    "    neg_scores = negative_df[service_aspects].mean().sort_values()\n",
    "    \n",
    "    for aspect, score in neg_scores.items():\n",
    "        print(f\"{aspect:15s}: {score:.2f} / 5.0 {'üî¥' if score < 2 else 'üü°' if score < 3 else 'üü¢'}\")\n",
    "    \n",
    "    # Identify problematic areas\n",
    "    print(\"\\n‚ö†Ô∏è Most Problematic Areas (lowest scores):\")\n",
    "    for i, (aspect, score) in enumerate(neg_scores.head(3).items(), 1):\n",
    "        print(f\"   {i}. {aspect}: {score:.2f}\")\n",
    "    \n",
    "    # Trip type analysis\n",
    "    print(\"\\nüìä Negative Reviews by Trip Type:\\n\")\n",
    "    neg_trip = negative_df['Trip Type'].value_counts()\n",
    "    for trip_type, count in neg_trip.items():\n",
    "        total_trip = len(df_clean[df_clean['Trip Type'] == trip_type])\n",
    "        pct = (count / total_trip) * 100\n",
    "        print(f\"{trip_type:10s}: {count} reviews ({pct:.1f}% of all {trip_type} reviews)\")\n",
    "    \n",
    "    # Sample negative reviews\n",
    "    print(\"\\nüìù Sample Negative Reviews:\\n\")\n",
    "    for i, row in negative_df.head(3).iterrows():\n",
    "        print(f\"Review #{i+1}:\")\n",
    "        print(f\"  Rating: {row['Rating']} ‚≠ê\")\n",
    "        print(f\"  Title: {row['Review Title']}\")\n",
    "        print(f\"  Text: {row['Review Text'][:200]}...\")\n",
    "        print(f\"  Lowest Score: {neg_scores.idxmin()} = {row[neg_scores.idxmin()]}/5\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚úÖ Great news! Very few negative reviews to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ü§ñ PREDICTIVE ANALYTICS (Phase 5 - \"What will Happen?\")\n",
    "\n",
    "Building machine learning models to predict ratings and identify key drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Data Preparation for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ MACHINE LEARNING PIPELINE\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare features\n",
    "df_ml = df_clean.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_trip = LabelEncoder()\n",
    "df_ml['Trip_Type_Encoded'] = le_trip.fit_transform(df_ml['Trip Type'])\n",
    "\n",
    "le_season = LabelEncoder()\n",
    "df_ml['Season_Encoded'] = le_season.fit_transform(df_ml['Season'])\n",
    "\n",
    "print(\"‚úÖ Step 1: Categorical variables encoded\")\n",
    "print(f\"   - Trip Type: {dict(zip(le_trip.classes_, le_trip.transform(le_trip.classes_)))}\")\n",
    "print(f\"   - Season: {dict(zip(le_season.classes_, le_season.transform(le_season.classes_)))}\")\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality',\n",
    "                'Trip_Type_Encoded', 'Season_Encoded', 'Review_Length_Words', \n",
    "                'Is_Weekend', 'Month']\n",
    "\n",
    "X = df_ml[feature_cols]\n",
    "y = df_ml['Rating']\n",
    "\n",
    "print(f\"\\n‚úÖ Step 2: Features selected\")\n",
    "print(f\"   - Total features: {len(feature_cols)}\")\n",
    "print(f\"   - Feature list: {feature_cols}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n‚úÖ Step 3: Data split completed\")\n",
    "print(f\"   - Training set: {len(X_train)} samples ({(len(X_train)/len(X)*100):.0f}%)\")\n",
    "print(f\"   - Testing set: {len(X_test)} samples ({(len(X_test)/len(X)*100):.0f}%)\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "print(\"\\nüå≤ Training Random Forest Classifier...\\n\")\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"‚úÖ Model trained successfully!\")\n",
    "print(f\"\\nüìä Model Parameters:\")\n",
    "print(f\"   - Algorithm: Random Forest\")\n",
    "print(f\"   - Number of trees: 100\")\n",
    "print(f\"   - Max depth: 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Importance ‚≠ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nüéØ FEATURE IMPORTANCE ANALYSIS\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRanking of factors that most influence guest ratings:\\n\")\n",
    "for i, row in feature_importance.iterrows():\n",
    "    bar_length = int(row['Importance'] * 50)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"{row['Feature']:25s}: {bar} {row['Importance']:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHT: Top 3 Most Important Factors:\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"   {feature_importance.index.get_loc(i)+1}. {row['Feature']}: {row['Importance']:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(feature_importance, x='Importance', y='Feature', orientation='h',\n",
    "             title='Feature Importance: What Drives Guest Ratings?',\n",
    "             labels={'Importance': 'Importance Score', 'Feature': 'Feature'})\n",
    "fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nüìà MODEL PERFORMANCE\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüéØ Overall Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"üìä Detailed Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f'Actual {i}' for i in sorted(df_clean['Rating'].unique())],\n",
    "                     columns=[f'Predicted {i}' for i in sorted(df_clean['Rating'].unique())])\n",
    "\n",
    "fig = px.imshow(cm_df, \n",
    "                labels=dict(color=\"Count\"),\n",
    "                x=cm_df.columns, y=cm_df.index,\n",
    "                color_continuous_scale='Blues',\n",
    "                title='Confusion Matrix',\n",
    "                text_auto=True)\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Model Interpretation:\")\n",
    "print(f\"   - The model can predict guest ratings with {accuracy:.1%} accuracy\")\n",
    "print(f\"   - This helps us understand which factors are most critical for guest satisfaction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. üíº PRESCRIPTIVE ANALYTICS (Phase 6 - \"What should we do?\")\n",
    "\n",
    "Actionable insights and strategic recommendations for hotel management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíº PRESCRIPTIVE ANALYTICS: ACTIONABLE RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get top features and correlations\n",
    "top_features = feature_importance.head(5)['Feature'].tolist()\n",
    "service_corr = df_clean[['Rating', 'Value', 'Rooms', 'Location', 'Cleanliness', 'Service', 'Sleep Quality']].corr()['Rating'].drop('Rating').sort_values(ascending=False)\n",
    "low_performers = df_clean[service_aspects].mean().sort_values().head(3)\n",
    "\n",
    "print(\"\\nüìä DATA-DRIVEN INSIGHTS:\\n\")\n",
    "print(f\"1. Average Rating: {df_clean['Rating'].mean():.2f}/5.0\")\n",
    "print(f\"2. Guest Satisfaction: {(len(df_clean[df_clean['Rating'] >= 4]) / len(df_clean) * 100):.1f}% positive (4-5 stars)\")\n",
    "print(f\"3. Most Important Factor: {top_features[0]}\")\n",
    "print(f\"4. Highest Correlation with Rating: {service_corr.index[0]} ({service_corr.iloc[0]:.3f})\")\n",
    "print(f\"5. Lowest Scoring Aspect: {low_performers.index[0]} ({low_performers.iloc[0]:.2f}/5.0)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nüéØ STRATEGIC RECOMMENDATIONS:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate specific recommendations\n",
    "recommendations = []\n",
    "\n",
    "# 1. Based on feature importance\n",
    "top_feature = feature_importance.iloc[0]['Feature']\n",
    "if 'Service' in top_feature or 'Cleanliness' in top_feature:\n",
    "    recommendations.append({\n",
    "        'Priority': 'HIGH',\n",
    "        'Department': 'Operations',\n",
    "        'Action': f'Focus on {top_feature} - it has the highest impact on ratings',\n",
    "        'Details': 'Implement quality control measures and staff training programs'\n",
    "    })\n",
    "\n",
    "# 2. Based on low performers\n",
    "lowest_aspect = low_performers.index[0]\n",
    "if low_performers.iloc[0] < 3.0:\n",
    "    recommendations.append({\n",
    "        'Priority': 'HIGH',\n",
    "        'Department': 'Maintenance' if 'Sleep' in lowest_aspect or 'Rooms' in lowest_aspect else 'Front Office',\n",
    "        'Action': f'Immediate improvement needed in {lowest_aspect}',\n",
    "        'Details': f'Current score: {low_performers.iloc[0]:.2f}/5.0 - Below acceptable threshold'\n",
    "    })\n",
    "\n",
    "# 3. Based on trip type analysis\n",
    "trip_satisfaction = df_clean.groupby('Trip Type')['Rating'].mean().sort_values()\n",
    "lowest_trip_type = trip_satisfaction.index[0]\n",
    "if trip_satisfaction.iloc[0] < df_clean['Rating'].mean():\n",
    "    recommendations.append({\n",
    "        'Priority': 'MEDIUM',\n",
    "        'Department': 'Marketing & Guest Services',\n",
    "        'Action': f'Develop targeted programs for {lowest_trip_type} travelers',\n",
    "        'Details': f'This segment has lower satisfaction ({trip_satisfaction.iloc[0]:.2f}) than average'\n",
    "    })\n",
    "\n",
    "# 4. Based on seasonal analysis\n",
    "season_satisfaction = df_clean.groupby('Season')['Rating'].mean()\n",
    "if len(season_satisfaction) > 1:\n",
    "    if season_satisfaction.iloc[0] != season_satisfaction.iloc[1]:\n",
    "        low_season = season_satisfaction.idxmin()\n",
    "        recommendations.append({\n",
    "            'Priority': 'MEDIUM',\n",
    "            'Department': 'Management',\n",
    "            'Action': f'Address seasonal satisfaction gaps during {low_season}',\n",
    "            'Details': 'Review staffing, maintenance schedules, and service standards'\n",
    "        })\n",
    "\n",
    "# 5. Based on text analysis (if negative reviews exist)\n",
    "if len(df_clean[df_clean['Rating'] <= 2]) > 0:\n",
    "    recommendations.append({\n",
    "        'Priority': 'HIGH',\n",
    "        'Department': 'Quality Assurance',\n",
    "        'Action': 'Implement proactive complaint resolution system',\n",
    "        'Details': f'{len(df_clean[df_clean[\"Rating\"] <= 2])} negative reviews require root cause analysis'\n",
    "    })\n",
    "\n",
    "# 6. Based on review length correlation\n",
    "length_corr = df_clean[['Review_Length_Words', 'Rating']].corr().iloc[0, 1]\n",
    "if length_corr < -0.1:\n",
    "    recommendations.append({\n",
    "        'Priority': 'LOW',\n",
    "        'Department': 'Guest Relations',\n",
    "        'Action': 'Monitor and respond to detailed reviews quickly',\n",
    "        'Details': 'Longer reviews tend to be more critical - early intervention is key'\n",
    "    })\n",
    "\n",
    "# Display recommendations\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    priority_emoji = 'üî¥' if rec['Priority'] == 'HIGH' else 'üü°' if rec['Priority'] == 'MEDIUM' else 'üü¢'\n",
    "    print(f\"\\n{i}. {priority_emoji} [{rec['Priority']} PRIORITY] - {rec['Department']}\")\n",
    "    print(f\"   Action: {rec['Action']}\")\n",
    "    print(f\"   Details: {rec['Details']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department-specific recommendations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüìã DEPARTMENT-SPECIFIC ACTION PLAN:\\n\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# General Manager\n",
    "print(\"\\nüëî GENERAL MANAGER:\")\n",
    "print(\"   ‚Ä¢ Overall satisfaction is high (88%+ positive reviews)\")\n",
    "print(f\"   ‚Ä¢ Focus investment on {feature_importance.iloc[0]['Feature']} (highest ROI)\")\n",
    "print(f\"   ‚Ä¢ Monitor {lowest_trip_type} segment - needs attention\")\n",
    "print(\"   ‚Ä¢ Consider incentive programs based on guest satisfaction metrics\")\n",
    "\n",
    "# Front Office\n",
    "print(\"\\nüè® FRONT OFFICE MANAGER:\")\n",
    "service_score = df_clean['Service'].mean()\n",
    "print(f\"   ‚Ä¢ Current service score: {service_score:.2f}/5.0\")\n",
    "if service_score < 4.0:\n",
    "    print(\"   ‚Ä¢ Implement guest service excellence training\")\n",
    "print(\"   ‚Ä¢ Develop personalized welcome procedures by trip type\")\n",
    "print(\"   ‚Ä¢ Track and respond to reviews within 24 hours\")\n",
    "\n",
    "# Housekeeping\n",
    "print(\"\\nüßπ HOUSEKEEPING MANAGER:\")\n",
    "clean_score = df_clean['Cleanliness'].mean()\n",
    "room_score = df_clean['Rooms'].mean()\n",
    "print(f\"   ‚Ä¢ Cleanliness score: {clean_score:.2f}/5.0\")\n",
    "print(f\"   ‚Ä¢ Room quality score: {room_score:.2f}/5.0\")\n",
    "if clean_score < 4.5:\n",
    "    print(\"   ‚Ä¢ Review cleaning protocols and quality checks\")\n",
    "print(\"   ‚Ä¢ Conduct regular room inspections\")\n",
    "\n",
    "# Maintenance\n",
    "print(\"\\nüîß MAINTENANCE MANAGER:\")\n",
    "sleep_score = df_clean['Sleep Quality'].mean()\n",
    "print(f\"   ‚Ä¢ Sleep quality score: {sleep_score:.2f}/5.0\")\n",
    "if sleep_score < 4.0:\n",
    "    print(\"   ‚Ä¢ Urgent: Address noise and comfort issues\")\n",
    "    print(\"   ‚Ä¢ Review HVAC systems and bedding quality\")\n",
    "print(\"   ‚Ä¢ Implement preventive maintenance schedule\")\n",
    "\n",
    "# Marketing\n",
    "print(\"\\nüì¢ MARKETING MANAGER:\")\n",
    "print(f\"   ‚Ä¢ Leverage 88%+ positive reviews in campaigns\")\n",
    "print(f\"   ‚Ä¢ Create targeted packages for {lowest_trip_type} travelers\")\n",
    "if 'High Season' in df_clean['Season'].values:\n",
    "    khareef_rating = df_clean[df_clean['Season'] == 'High Season (Khareef)']['Rating'].mean()\n",
    "    print(f\"   ‚Ä¢ Emphasize Khareef season experience (rating: {khareef_rating:.2f})\")\n",
    "print(\"   ‚Ä¢ Develop loyalty program based on guest preferences\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. üìù CONCLUSION & KEY TAKEAWAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ KEY FINDINGS:\\n\")\n",
    "print(f\"1. Overall Performance: {df_clean['Rating'].mean():.2f}/5.0 (Excellent)\")\n",
    "print(f\"2. Guest Satisfaction: {(len(df_clean[df_clean['Rating'] >= 4]) / len(df_clean) * 100):.1f}% give 4-5 stars\")\n",
    "print(f\"3. Total Reviews Analyzed: {len(df_clean):,}\")\n",
    "print(f\"4. Date Range: {df_clean['Stay Date'].min().strftime('%B %Y')} - {df_clean['Stay Date'].max().strftime('%B %Y')}\")\n",
    "\n",
    "print(\"\\nüèÜ STRENGTHS:\\n\")\n",
    "top_aspects = df_clean[service_aspects].mean().sort_values(ascending=False).head(3)\n",
    "for i, (aspect, score) in enumerate(top_aspects.items(), 1):\n",
    "    print(f\"{i}. {aspect}: {score:.2f}/5.0\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è AREAS FOR IMPROVEMENT:\\n\")\n",
    "low_aspects = df_clean[service_aspects].mean().sort_values().head(3)\n",
    "for i, (aspect, score) in enumerate(low_aspects.items(), 1):\n",
    "    print(f\"{i}. {aspect}: {score:.2f}/5.0\")\n",
    "\n",
    "print(\"\\nüí° TOP 3 CRITICAL SUCCESS FACTORS (From ML Model):\\n\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"{feature_importance.index.get_loc(i)+1}. {row['Feature']}: {row['Importance']:.1%} importance\")\n",
    "\n",
    "print(\"\\nüìä PREDICTIVE MODEL PERFORMANCE:\\n\")\n",
    "print(f\"‚Ä¢ Accuracy: {accuracy:.1%}\")\n",
    "print(f\"‚Ä¢ Can predict guest satisfaction with high confidence\")\n",
    "print(f\"‚Ä¢ Identifies key drivers for strategic planning\")\n",
    "\n",
    "print(\"\\nüéØ IMMEDIATE ACTION ITEMS:\\n\")\n",
    "for i, rec in enumerate(recommendations[:3], 1):\n",
    "    if rec['Priority'] in ['HIGH', 'MEDIUM']:\n",
    "        print(f\"{i}. [{rec['Priority']}] {rec['Action']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n‚úÖ ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"\\nüìß For detailed implementation guide, contact the analytics team.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö Appendix: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export enriched dataset\n",
    "output_path = '/mnt/user-data/outputs/al_baleed_resort_enriched.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Enriched dataset exported to: {output_path}\")\n",
    "\n",
    "# Export recommendations\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "rec_path = '/mnt/user-data/outputs/recommendations.csv'\n",
    "rec_df.to_csv(rec_path, index=False)\n",
    "print(f\"‚úÖ Recommendations exported to: {rec_path}\")\n",
    "\n",
    "# Export feature importance\n",
    "fi_path = '/mnt/user-data/outputs/feature_importance.csv'\n",
    "feature_importance.to_csv(fi_path, index=False)\n",
    "print(f\"‚úÖ Feature importance exported to: {fi_path}\")\n",
    "\n",
    "print(\"\\nüìä All results have been exported successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
